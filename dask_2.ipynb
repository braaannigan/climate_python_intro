{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "Dask does two things that NumPy and Pandas don't:\n",
    "- it allows you to build *task graphs* that set out a plan for executing an operation\n",
    "- it manages the parallelization of these operations\n",
    "\n",
    "In practice, this means that you can:\n",
    "- work with datasets that are larger than memory without needing to micro-manage the file input-output\n",
    "- operate in parallel\n",
    "- but still write code that is recognisible from pandas and numpy\n",
    "\n",
    "Dask is also built into xarray as an optional dependancy.\n",
    "\n",
    "For reference, the calculations below are carried out on a workstation with 8 CPU cores and 23 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task graphs and lazy evaluation\n",
    "When you call a function on a numpy array, the function is evaluated immediately.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2699025622958837"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum( np.random.rand( 10 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach of evaluating immediately is known as **eager evaluation**.\n",
    "\n",
    "When you call a function on a dask array, the function is *not* evaulated immediately.  Instead, calling the function means that dask creates a plan for how it would carry out this operation. This plan is known as a **task graph**. This approach of deferring evaluating is known as **lazy evaluation**.  \n",
    "\n",
    "The following example shows a simple example where the ultimate computation is to 1) create a random matrix 2) increase all the elements by 1 and 3) add all the elements together.\n",
    "\n",
    "The task graph image will **not** work on your machine unless [you install special packages to do so.](https://stackoverflow.com/a/43744112/5387991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Drawing dask graphs requires the `graphviz` python library and the `graphviz` system library to be installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/site-packages/dask/utils.py\u001b[0m in \u001b[0;36mimport_required\u001b[0;34m(mod_name, error_msg)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2e1aaef073e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Output the task graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(self, filename, format, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[1;32m     78\u001b[0m         return visualize(self, filename=filename, format=format,\n\u001b[0;32m---> 79\u001b[0;31m                          optimize_graph=optimize_graph, **kwargs)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \"\"\"\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mydask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/site-packages/dask/dot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m graphviz = import_required(\"graphviz\", \"Drawing dask graphs requires the \"\n\u001b[0m\u001b[1;32m     13\u001b[0m                                        \u001b[0;34m\"`graphviz` python library and the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                        \u001b[0;34m\"`graphviz` system library to be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/work3/lib/python3.6/site-packages/dask/utils.py\u001b[0m in \u001b[0;36mimport_required\u001b[0;34m(mod_name, error_msg)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Drawing dask graphs requires the `graphviz` python library and the `graphviz` system library to be installed."
     ]
    }
   ],
   "source": [
    "# Define a function that increases all the elements of x by 1\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "# Create a dask array with 9 random elements divided into a single chunk of 9 elements\n",
    "arr = da.from_array(np.random.rand(9),chunks=(9))\n",
    "# Increase all the elements by 1\n",
    "arr = inc(arr)\n",
    "# Add all the elements together\n",
    "arr = da.sum(arr)\n",
    "# Output the task graph\n",
    "arr.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the evaluation of the task graph has still not occurred - not even the initial stage of creating the random matrix.\n",
    "\n",
    "To get dask to trigger the evaluation, use the ```.compute``` method on ```arr```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.865100532825501"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the syntax is different when we use dask in xarray. In xarray case the ```.load()``` method triggers the evaluation, but when using dask alone ```.compute()``` triggers execution.\n",
    "\n",
    "The task graph visualised above is a python dictionary setting out the chain of calculations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelisation\n",
    "Dask also manages the execution of the task graph in parallel.  When executing in parallel you must specify the way that your data should be partitioned - the partions are known as *chunks*.\n",
    "\n",
    "To illustrate parallel execution, we repeat the calculation above with a random matrix, but this time we split the array with 9 total elements into chunks with 3 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that increases all the elements of x by 1\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "# Create a dask array with 9 random elements divided into a single chunk of 9 elements\n",
    "arr = da.from_array(np.random.rand(9),chunks=(3,))\n",
    "# Increase all the elements by 1\n",
    "arr = inc(arr)\n",
    "# Add all the elements together\n",
    "arr = da.sum(arr)\n",
    "# Output the task graph\n",
    "#arr.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask now has a task graph that carries out the array creation and incrementing by 1 separately in each of the three chunks.  In the step where the summing of the whole array occurs, dask plans to sum each of the chunks separately to get sub-totals and then to sum the the three sub-totals together.  This reduces the amount of data that must be transferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and disadvantages of dask\n",
    "The ability to carry out operations in parallel is clearly an advantage of dask.  However, \n",
    "- creating the task graph;\n",
    "- carrying out calculations on smaller chunks of data; and\n",
    "- transferring the results of calculations from the chunks to each other\n",
    "\n",
    "all carry computational cost.  \n",
    "\n",
    "**If your dataset fits comfortably in memory, it is better to carry out the calculation using numpy.**\n",
    "\n",
    "We can compare the performance of numpy and dask for such a calculation where the array fits comfortably in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803 ms ± 1.75 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Numpy example\n",
    "rand_arr = np.random.rand( 500,500,100)\n",
    "%timeit np.mean(rand_arr,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare this with a similar calculation using dask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.8 ms ± 1.71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Dask example where the task graph is created first and we only time the computation\n",
    "dask_rand_arr = da.from_array( rand_arr, chunks = (100,100,100))\n",
    "y = da.mean(dask_rand_arr, axis = 1)\n",
    "%timeit y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case dask takes twice as long.\n",
    "\n",
    "Be aware that these kinds of performance comparisons generalise poorly to other problems.  The size of the data, the number of cores available and the nature of the calculation all have a major effect on the performance you experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **real advantages** of dask arise when:\n",
    "- your dataset is bigger than the memory you have available (in practice dask may start becoming advantageous from when your dataset is 1/3 of your available memory)\n",
    "- you have multiple cores available on your computer.\n",
    "\n",
    "A major advantage is that the task scheduler in dask manages the process of reading data from disk into memory for each chunk.  This can reduce the amount of micro-management that you need to do yourself.\n",
    "\n",
    "This example shows how easy it is to do such out-of-core processing on a very large array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of array in gigabytes 320.0\n"
     ]
    }
   ],
   "source": [
    "# Create very large array\n",
    "# Cut into 1000x1000 sized chunks\n",
    "x = da.random.normal(0, 1, size=(200000, 200000),  \n",
    "                              chunks=(1000, 1000))    \n",
    "\n",
    "# Get size of array\n",
    "print(\"Size of array in gigabytes\", x.nbytes / 1e9)   \n",
    "\n",
    "# Take mean on first axis (indexing is just to reduce the amount output to the screen)\n",
    "y = x.mean(axis=0)[::100000]                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we initialise an enourmous array that would occupy 320 Gb in memory.  We divide this array into chunks that are 1000 x 1000.  We then take the mean of this array along the first axis and output a small subset of the outputs.\n",
    "\n",
    "As we have not yet called ```.compute()``` on y, **none of this has yet happened**.  Instead, dask has created a task graphy setting out how it would go about this.\n",
    "\n",
    "We can now trigger the calculation.  Before doing so for the first time, it is a good idea to remove some of the zeros from the size of the array $x$ first to check that the calculation won't overwhelm your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 1.01 s, total: 23.2 s\n",
      "Wall time: 4.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 10.00043669,  10.00018279])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time  y.compute();     # Time to compute the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *user* time is the total amount of time the CPUs spent doing the calculation.\n",
    "\n",
    "The *sys* time is the overhead for the dask scheduler.  \n",
    "\n",
    "The *total* time is the sum of the *user* and *sys* time.\n",
    "\n",
    "The most important output is the *Wall time* - this is the actual amout of time the calculation took to run.  The Wall time is much less than the total CPU time because the CPUs are operating in parallel.\n",
    "\n",
    "A wall-clock time of just a few seconds for a calculation on a 320 GB array is quite impressive.  However, a similar calculation on a dataset stored in netcdf files will likely take much longer.  This longer time with netcdf files is because the data would have to be read from the hard disk, whereas the random array above was just initialised directly in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting chunk sizes\n",
    "The chunk sizes set how the operations are parallelised.\n",
    "\n",
    "More chunks -> more parallel operations, but more computational overhead\n",
    "\n",
    "Chunk size depends on your system.  A rule of thumb is to have chunks with size 100 Mb - 500 Mb.\n",
    "\n",
    "The chunk shape can affect performance.  If you are taking a mean in the x-direction, for example, then having each chunk span the x-direction can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = da.random.normal(10, 0.1, size=(4000, 3000,300),   # 4000x3000 array with 3000 time steps \n",
    "                              chunks=(100, 100,10))   # Short chunks on the first dimension\n",
    "y = temp.mean(axis=0)[::1000,::1000]                         # Take mean on first dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.4s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "with ProgressBar():\n",
    "    y.compute();     # Time to compute the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of temperature array in gigabytes 28.8\n"
     ]
    }
   ],
   "source": [
    "temp = da.random.normal(10, 0.1, size=(4000, 3000,300),   # 4000x3000 array with 3000 time steps \n",
    "                              chunks=(1000, 100,10))   # Cut into 1000x1000 sized chunks\n",
    "y = temp.mean(axis=0)[::1000,::1000]                         # Perform NumPy-style operation\n",
    "print(\"Size of temperature array in gigabytes\", temp.nbytes / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    }
   ],
   "source": [
    "# We can add a progress bar to get a sense of how quickly the calculation is proceeding.\n",
    "with ProgressBar():\n",
    "    y.compute();     # Time to compute the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the chunk shape and size is important, the performance may be dominated by how your data is stored on disk.  The time needed to open and close a netcdf file may be as long as the time needed to read the data in the file!  On account of this overhead, if you set your chunk shape and size in such a way that many file openings and closings are required, then it may overwhelm any performance advantage once the data is in memory.\n",
    "\n",
    "Ulimately, the right solution will depend on your system and your problem, so you need to experiment.\n",
    "\n",
    "## Linear algebra\n",
    "Dask also has algorithms to handle common linear algebra operations in parallel.  For example, you can do a fast fourier transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = da.from_array(np.linspace(0,10*np.pi, 300), chunks=(300) )\n",
    "signal = np.cos(0.5*t) + np.cos(3*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = da.fft.fft(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other aspects of dask\n",
    "As well as the dask.array, dask can deal with dataframes and arbitrary tasks.\n",
    "\n",
    "### Delayed\n",
    "The dask.delayed module allows you to create arbitrary task graphs.  This is not so useful in climate research, where we typically work with arrays or dataframes and so dask.array or dask.dataframe are most useful.  However, it may be useful for other tasks, such as processing text-based data in operations that cannot be vectorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "# Define a function and decorate it with @delayed\n",
    "@delayed()\n",
    "def add(a,b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the function has been created with the @delayed wrapper, it can be called as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = add(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with dask.array, this operation has just created a task graph.  To execute it the ```.compute()``` method must be called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work3",
   "language": "python",
   "name": "work3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
